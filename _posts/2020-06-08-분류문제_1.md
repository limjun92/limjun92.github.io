---
header:
  teaser: /assets/images/ai/로지스틱시그모이드.PNG
title:  "머신러닝 - 분류 문제_1"
excerpt: "AI_Algorithm, 로지스틱 회귀, 서포트 벡터 머신"
toc: true
toc_sticky: true
categories:
  - AI_개념
tags:
  - AI
  - AI_Algorithm
last_modified_at: 2020-06-08
---

* 머신러닝 알고리즘의 선택 기준

      1. 변수의 특성
      2. 데이터의 개수
      3. 노이즈 데이터의 양
      4. 클래스의 선형적 구분 여부

* 머신러닝 알고리즘 훈련을 위한 단계

      1. 변수를 선택하고 훈련데이터를 수집
      2. 모델의 성능 지표를 선택
      3. 분류 모델과 최적화 알고리즘을 선택
      4. 모뎅의 성능 평가
      5. 모델 튜닝

# 퍼셉트론
  * 여러개의 입력을 받아 각각의 값에 가중치를 곱한 후,
    모두 더한 것이 출력되는 형태의 모델
  * 단순모델
  * **선형적**이다. 선형적으로 구분되지 않는 데이터에는 수렴하지 못한다는 단점
      
# 로지스틱 회귀
  
      ''분류를 확률로 생각하는 방식''
  * **퍼셉트론의 간단함을 유지**하면서 **비선형적 문제 해결 가능**  
  * 어느 클래스에 분류 되는지 구하는 것  => 함수 필요  
  
  ## 로지스틱시그모이드함수  
  
  ![로지스틱시그모이드함수](/assets/images/ai/로지스틱시그모이드함수.PNG)  
  ![로지스틱시그모이드함수2](/assets/images/ai/로지스틱시그모이드함수2.PNG)  
  ![로지스틱시그모이드함수0](/assets/images/ai/로지스틱시그모이드함수0.PNG)
  * [로지스틱시그모이드 그래프구현 예제](https://github.com/limjun92/limjun92.github.io/blob/master/ipynb/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C.ipynb)
      
    어떠한 입력값이 들어와도 0 ~ 1 사이의 값을 반환 이를 확률처럼 다룰수 있음
    P(y = 1|x) = f(x)
    x값이 주어졌을때 y가 1일 확률 ex) f(x) = 0.7는 가로로 길확률이 0.7
    * ![로지스틱시그모이드함수3](/img/로지스틱시그모이드함수3.PNG)
    * 결정경계
    
1. 목적함구 정의 
2. 미분
3. 매개변수 갱신식 구하기
    
* 서포트 벡터 머신
  * 가력한 학습 알고리즘
  * SVM 마진을 최대화
  * 초평면(결정경계)
  * 마진은 초평면과 가장 가까운 훈련 데이터(서포트 벡터)들 사이의 거리
  * 일반화를 진행했을때 오차가 낮아지는 경향을 보안
  * 2차원 => 3차원 비선형 결정경계에서도 사용가능함
  * 단점
    * 계산비용 => 컴퓨터 비용이 높다
    * 커널 기법으로 어느정도 해결 가능
    
