# Seq2Seq 모델

* 문장을 입력받아 문장을 출력받는다

* 좋은 아침입니다. -> Seq2seq -> Good Morning

* 인코더 -> 디코더

  * 인코더 : LSTM 연산을 하고 장기기억(hidden state)과 단기기억(cell state)을 디코더로 들어간다

  * 디코더 : <start>, 장기기억, 단기기억이 들어가면서 단어를 추측 다들어가면 문장이 끝나는게 옳다는 <end>  
  가장 높은 확률의 단어를 뽑아준다
  
* **한글문장에 대한 정보값과 내가 가진 단어를 이용해서 다음 단어를 추측한다.**

* 정보를 토대로 다음에 나올 단어를 추측함 

# cording

http://semanticweb.kaist.ac.kr/home/index.php/KAIST_Corpus
