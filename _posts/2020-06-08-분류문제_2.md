---
title:  "머신러닝 - 분류 문제(결정 트리 학습, K-최근접 이웃(KNN))"
excerpt: "AI_Algorithm"

categories:
  - AI_개념
tags:
  - AI
  - AI_Algorithm
last_modified_at: 2020-06-08
---

* 결정 트리 학습
  * 설명이 중요할때 유용
  * ![결정트리](/img/결정트리.PNG)   
  * 범주형 변수
  * 실수형 변수
  * 리프노드가 순수해질때까지 자식노드에서 분할 작업을 반복
  * 깊은 트리가 만들어지면 과적합이 생김 => 트리의 최대깊이를 제한(가지치기)
  * 목적함수의 목적 => 정보이득(IG) 최대화
    * 가장 정보가 풍부한 특성으로 노드를 나누기 위함
    * 트리 알고리즘으로 최적화
    * 자식 노드의 불순도가 낮을수록 
    * ![결정트리2](/img/결정트리2.PNG)   
    * ![결정트리3](/img/결정트리3.PNG)   
    1. 엔트로피 
        * 트리의 상호 의존 정보를 최대화 하는 것
    2. 지니 불순도 
        * 엔트로피와 반대되는 개념
        * 잘못 분류될 확률을 최소화 하기 위한 기준
    3. 분류오차
        * 노드의 클래스 확률 변화에 둔감 => 잘 사용안한다
      
 * K-최근접 이웃(KNN)
   * 훈련과정을 진행하지 않은 머신러닝 알고리즘
   * 알고리즘을 실행할 때마다 모든 학습데이터를 통해 분류를 진행
   * 매번 실행할 때 마다 학습 데이터 필요
   * 빠르게 결과를 살펴볼수 있는 장점이 있다.
   
   1. 숫자 K와 거리 측정 기준을 선택(유클리디안 거리 측정 방식)
   2. 분류하려는 미지의 데이터에서 K개의 최근접 이웃을 찾습니다.
   3. 다수격 투표를 진행, 투표 결과에 따라 미지의 데이터 클래스 레이블을 할당
   
   * 과적합과 과소적합 사이에서 올바른 K값을 찾는 것이 매우 중요
   * 차원의 저주 
     * 고정된 크기의 훈련 데이터셋 차원이 늘어남에 따라 특성 공간이 점점 희소해지는 현상
   * 올바른 변수 선택
   * 차원 축소 기법
   
   
