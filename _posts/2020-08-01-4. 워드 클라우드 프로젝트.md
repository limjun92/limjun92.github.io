---
title:  "4. 워드 클라우드 프로젝트"
excerpt: ""
toc: true
toc_sticky: true
categories:
  - Web
  - Crawling
tags:

last_modified_at: 2020-08-01
---

# 워드클라우드

* 데이터에서 단어 빈도를 분석하여 시각화 하는 기법
* 텍스트 데이터 필요

# 형태소 추출

* 한국어 단어에 붙는 어미와 조사를 제거하고, 단어의  
  어근만 집계되도록 하는 형태소 추출 과정이 필요하다
  
## mecab
* 한국어 자연어 처리 라이브러리

```python
from mecab import MeCab
m = MeCab()
# 객체 생성

text = "광화문역 주변에 있는 맛집을 알고 싶어요. 정보를 얻을 수 있을까요?"

print(m.morphs(text))
# 문장을 형태소로 나누어 리스트로 반환합니다
# ['광화문역', '주변', '에', '있', '는', '맛집', '을', '알', '고', '싶', '어요', '.', '정보', '를', '얻', '을', '수', '있', '을까요', '?']
print(m.nouns(text))
# 문장을 형태소로 나누고 명사만 추출한다
['광화문역', '주변', '맛집', '정보', '수']
print(m.pos(text))
# 문장을 형태고로 나누고 품사에 정보를 포함하여 반환한다
[('광화문역', 'NNP'), ('주변', 'NNG'), ('에', 'JKB'), ('있', 'VV'), ('는', 'ETM'), ('맛집', 'NNG'), ('을', 'JKO'), ('알', 'VV'), ('고', 'EC'), ('싶', 'VX'), ('어요', 'EF'), ('.', 'SF'), ('정보', 'NNG'), ('를', 'JKO'), ('얻', 'VV'), ('을', 'ETM'), ('수', 'NNB'), ('있', 'VV'), ('을까요', 'EF'), ('?', 'SF')]
```
