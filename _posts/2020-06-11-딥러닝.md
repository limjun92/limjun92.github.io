---
header:
  teaser: /assets/images/ai/딥러닝.PNG
title:  "머신러닝 - 딥러닝"
excerpt: "딥러닝, 역전파"
toc: true
toc_sticky: true
categories:
  - AI_개념
tags:
  - AI
  - 딥러닝
last_modified_at: 2020-06-11
---

# 1. 딥러닝(심층신경망)

* 인간의 신경망 이론
* **인공 신경망**
* 계층 구조
* 입력층과 출력층 사이에 하나이상의 은닉층을 가지고 있는 **심층 신경망** 

![딥러닝](/assets/images/ai/딥러닝.PNG)  

# 2. 인공 신경망

    인간의 뇌를 형성하는 뉴런의 집합체를 수학 모델로 표현한 것
  
* 인간의 뇌 구조 모방하여 모델링한 수학적 모델 
* 다수의 입력 => 신호를 합한하여 계산 => 출력 결정 
* 수상돌기 => 입력   세포체, 노드 => 입력합산 지점   축삭 => 출력  

![인공신경망](/assets/images/ai/인공신경망.PNG) 

## 합성곱 신경망 
  * 이미지 인식(CNN기반)
## 순환 신경망(Recurrent Neural Network)

    이전의 기억을 활용할 줄 알아야 한다.
    
  * 음성, text
  * LSTM(Long Short-Term Memory), GRU(Gated Recurrent Unit)로 발전
  
* * *

* 딥러닝 원리
  * MCP
  
      신경세포를 이진 출력을 내는 간단한 논리 회로로 표현
      
  * perceptron
  
      입력을 받아 계산하고 출력을 반환  
    ![perceptron](/assets/images/ai/perceptron.PNG)  
  
  * 신경망은 뉴런이 여러개 모여 레이어를 구성한 후, 이 레이어가 다시 모여 구성된 형태
  * 하나의 뉴런에는 가중치와 활성화 함수가 있다
  * ![활성화](/assets/images/ai/활성화.PNG)
  * error = (기대출력) - (실제출력)
  * 학습률 => 가중치 조정을 위한 하이퍼파라미터 
  * w(가중치) = w + X * 0.1 * error  경사하강법
  * x(입력값)이 0일 경우 편향을 추가
  
* AND OR XOR
  * 다층 퍼셉트론 => 딥러닝의 뿌리
    * 인공지능을 가속화 시켜준 계기
  * 역전파 알고리즘
  
* 신경망의 목적
  * 손실함수가 최솟값일때의 파라미터를 찾아 올바른 학습 결과를 내는 것
  * 회귀분석, 로지스틱회귀와 기본개념이 같다
  * 회귀분석보다 파라미터수가 더 많은 편

* 역전파
  * 뉴런의 가중치를 효율적을 조정하기 위하여 거꾸로 무엇인가를 전파하는 방식
  * 순전파 & 역전파
  * 출력값과 지도 데이터 사이의 오차를 이용해 출력층에서 입력층쪽으로 가중치를 조정한다
  * 역방향 미분이라고도 한다
  * 시그모이드, 소프트맥스 =>  기울기 소멸(신경망이 깊어질수록 학습이 잘 되지 않는 문제가 발생)
  * ReLU 입력이 음수-> 0 입력이 양수 -> 값 그대로 => 기울기 소명에 어느정도 면역
