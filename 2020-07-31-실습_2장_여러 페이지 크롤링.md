---
title:  "실습_2장_여러 페이지 크롤링"
excerpt: ""
toc: true
toc_sticky: true
categories:
  - Web
  - Crawling
tags:

last_modified_at: 2020-07-31
---

# 여러 페이지의 기사 제목 수집

```python

import requests
from bs4 import BeautifulSoup

def crawling(soup) :
    result = []
    ul = soup.find("ul",class_="list_news").find_all("span",class_="tit")
    
    for i in ul:
        result.append(i.get_text())
    
    return result

def main() :
    answer = []
    url = "https://sports.donga.com/ent"
    
    for i in range(0, 5):
        #===================핵심내용========================
        req = requests.get(url, params = {'p' : i*20+1})
        # https://sports.donga.com/ent?p=1&c=02
        # params를 사용해서 p값을 변경해준다
        #==================================================
        soup = BeautifulSoup(req.text, "html.parser")
        
        answer += crawling(soup)

    print(answer)

if __name__ == "__main__" :
    main()
```

# 각 기사의 href 수집하기

```python

import requests
from bs4 import BeautifulSoup

def get_href(soup) :
    result = []
    ul = soup.find("ul",class_="list_news").find_all("span",class_="tit")
    
    for i in ul:
        # =================== 핵심내용 =============================
        print(i.find("a").attrs)
        # attrs를 사용해서 속성과 값을 딕셔너리 형태로 확인할 수 있다
        print(i.find("a")["href"])
        # "href"를 key값으로 사용해서 하이퍼링크를 조회할 수 있다
        # ==========================================================
        result.append(i.find("a")["href"])
        
    return result

def main():
    list_href = []

    url = "https://sports.donga.com/ent?p=1&c=02"
    result = requests.get(url)
    soup = BeautifulSoup(result.text, "html.parser")

    print(get_href(soup))

if __name__ == "__main__":
    main()
    
```

# 네이트 최신뉴스 href 수집하기

```python 

import requests
from bs4 import BeautifulSoup

    
def get_href(soup) :
    result = []
    div = soup.find("div",class_="postSubjectContent").find_all("a")
    
    for i in div:
        result.append("https:"+i["href"])
    
    return result
    
def main() :
    list_href = []
    
    url = "https://news.nate.com/recent?mid=n0100"
    req = requests.get(url)
    soup = BeautifulSoup(req.text, "html.parser")
    
    list_href = get_href(soup)
    
    print(list_href)

if __name__ == "__main__" :
    main()

```
